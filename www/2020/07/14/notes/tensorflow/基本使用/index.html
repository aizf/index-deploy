<h1 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h1><p>使用 TensorFlow, 你必须明白 TensorFlow:</p>
<ul>
<li>使用<strong>图 (graph)</strong> 来表示计算任务.</li>
<li>在被称之为 <strong>会话 (Session)</strong> 的上下文 (context) 中执行图.</li>
<li>使用** tensor **表示数据.</li>
<li>通过 <strong>变量 (Variable)</strong> 维护状态.</li>
<li>使用 <strong>feed</strong> 和 <strong>fetch</strong> 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>
</ul>
<h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>TensorFlow 是一个编程系统, 使用<strong>图</strong>来表示计算任务. 图中的<strong>节点</strong>被称之为 <strong>op</strong> (operation 的缩写). 一个 <strong>op</strong> 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].</p>
<p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, <strong>图必须在 会话 里被启动</strong>. <strong>会话 将图的 op 分发</strong>到诸如 CPU 或 GPU 之类的 设备 上, <strong>同时提供执行 op 的方法</strong>. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象;</p>
<h1 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h1><p>TensorFlow 程序通常被组织成一个<strong>构建阶段</strong>和一个<strong>执行阶段</strong>. </p>
<ul>
<li>在构建阶段, op 的执行步骤 被描述成一个图. </li>
<li>在执行阶段, 使用会话执行执行图中的 op.</li>
</ul>
<h1 id="构建图"><a href="#构建图" class="headerlink" title="构建图"></a>构建图</h1><p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入. 源 op 的输出被传递给其它 op 做运算.<br>TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.</p>
<div class="hljs"><pre><code class="hljs vala">import tensorflow as tf

<span class="hljs-meta"># 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点</span>
<span class="hljs-meta"># 加到默认图中.</span>
<span class="hljs-meta">#</span>
<span class="hljs-meta"># 构造器的返回值代表该常量 op 的返回值.</span>
matrix1 = tf.constant([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]])

<span class="hljs-meta"># 创建另外一个常量 op, 产生一个 2x1 矩阵.</span>
matrix2 = tf.constant([[<span class="hljs-number">2.</span>],[<span class="hljs-number">2.</span>]])

<span class="hljs-meta"># 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入.</span>
<span class="hljs-meta"># 返回值 'product' 代表矩阵乘法的结果.</span>
product = tf.matmul(matrix1, matrix2)</code></pre></div>
<p>为了真正进行矩阵相乘运算, 并得到矩阵乘法的 结果, 你必须在会话里启动这个图.</p>
<h1 id="在一个会话中启动图"><a href="#在一个会话中启动图" class="headerlink" title="在一个会话中启动图"></a>在一个会话中启动图</h1><p>启动图的第一步是创建一个 Session 对象, 如果无任何创建参数, 会话构造器将启动默认图.</p>
<div class="hljs"><pre><code class="hljs vala"><span class="hljs-meta"># 启动默认图.</span>
sess = tf.Session()

<span class="hljs-meta"># 调用 sess 的 'run()' 方法来执行矩阵乘法 op, 传入 'product' 作为该方法的参数. </span>
<span class="hljs-meta"># 上面提到, 'product' 代表了矩阵乘法 op 的输出, 传入它是向方法表明, 我们希望取回</span>
<span class="hljs-meta"># 矩阵乘法 op 的输出.</span>
<span class="hljs-meta">#</span>
<span class="hljs-meta"># 整个执行过程是自动化的, 会话负责传递 op 所需的全部输入. op 通常是并发执行的.</span>
<span class="hljs-meta"># </span>
<span class="hljs-meta"># 函数调用 'run(product)' 触发了图中三个 op (两个常量 op 和一个矩阵乘法 op) 的执行.</span>
<span class="hljs-meta">#</span>
<span class="hljs-meta"># 返回值 'result' 是一个 numpy `ndarray` 对象.</span>
result = sess.run(product)
print result
<span class="hljs-meta"># ==&gt; [[ 12.]]</span>

<span class="hljs-meta"># 任务完成, 关闭会话.</span>
sess.close()</code></pre></div>
<p>Session 对象在使用完后需要关闭以释放资源. <strong>除了显式调用 close 外, 也可以使用 “with” 代码块</strong> 来自动完成关闭动作.</p>
<div class="hljs"><pre><code class="hljs applescript"><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:
  <span class="hljs-literal">result</span> = sess.<span class="hljs-built_in">run</span>([product])
  print <span class="hljs-literal">result</span></code></pre></div>
<p>在实现上, TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU). 一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测. 如果检测到 GPU, TensorFlow <strong>会尽可能地利用找到的第一个 GPU</strong> 来执行操作.</p>
<p>如果机器上有超过一个可用的 GPU,** 除第一个外的其它 GPU 默认是不参与计算的**. 为了让 TensorFlow 使用这些 GPU, 你必须将 op 明确指派给它们执行. with…Device 语句用来指派特定的 CPU 或 GPU 执行操作:</p>
<div class="hljs"><pre><code class="hljs lua">with tf.Session() as sess:
  with tf.device(<span class="hljs-string">"/gpu:1"</span>):
    matrix1 = tf.constant(<span class="hljs-string">[[3., 3.]]</span>)
    matrix2 = tf.constant(<span class="hljs-string">[[2.],[2.]]</span>)
    product = tf.matmul(matrix1, matrix2)
    ...</code></pre></div>
<p>设备用字符串进行标识. 目前支持的设备包括:</p>
<ul>
<li>“/cpu:0”: 机器的 CPU.</li>
<li>“/gpu:0”: 机器的第一个 GPU, 如果有的话.</li>
<li>“/gpu:1”: 机器的第二个 GPU, 以此类推.</li>
</ul>
<h1 id="交互式使用"><a href="#交互式使用" class="headerlink" title="交互式使用"></a>交互式使用</h1><p>文档中的 Python 示例使用一个会话 Session 来 启动图<br>为了便于使用诸如 IPython 之类的 Python 交互环境, 可以使用 InteractiveSession 代替 Session 类, 使用 Tensor.eval() 和 Operation.run() 方法代替 Session.run(). 这样可以避免使用一个变量来持有会话.</p>
<div class="hljs"><pre><code class="hljs properties"><span class="hljs-comment"># 进入一个交互式 TensorFlow 会话.</span>
<span class="hljs-attr">import</span> <span class="hljs-string">tensorflow as tf</span>
<span class="hljs-attr">sess</span> = <span class="hljs-string">tf.InteractiveSession()</span>

<span class="hljs-attr">x</span> = <span class="hljs-string">tf.Variable([1.0, 2.0])</span>
<span class="hljs-attr">a</span> = <span class="hljs-string">tf.constant([3.0, 3.0])</span>

<span class="hljs-comment"># 使用初始化器 initializer op 的 run() 方法初始化 'x' </span>
<span class="hljs-attr">x.initializer.run()</span>

<span class="hljs-comment"># 增加一个减法 sub op, 从 'x' 减去 'a'. 运行减法 op, 输出结果 </span>
<span class="hljs-attr">sub</span> = <span class="hljs-string">tf.sub(x, a)</span>
<span class="hljs-attr">print</span> <span class="hljs-string">sub.eval()</span>
<span class="hljs-comment"># ==&gt; [-2. -1.]</span></code></pre></div>
<h1 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h1><p>TensorFlow 程序使用 tensor 数据结构来代表所有的数据</p>
<p>可以把 TensorFlow tensor 看作是一个 n 维的数组或列表. 一个 tensor 包含一个静态类型 rank, 和 一个 shape</p>
<h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><p>变量维护图执行过程中的状态信息. 下面的例子演示了如何使用变量实现一个简单的计数器. </p>
<div class="hljs"><pre><code class="hljs pf"><span class="hljs-comment"># 创建一个变量, 初始化为标量 0.</span>
<span class="hljs-keyword">state</span> = tf.Variable(<span class="hljs-number">0</span>, name=<span class="hljs-string">"counter"</span>)

<span class="hljs-comment"># 创建一个 op, 其作用是使 state 增加 1</span>

one = tf.constant(<span class="hljs-number">1</span>)
new_value = tf.add(<span class="hljs-keyword">state</span>, one)
update = tf.assign(<span class="hljs-keyword">state</span>, new_value)

<span class="hljs-comment"># 启动图后, 变量必须先经过`初始化` (init) op 初始化,</span>
<span class="hljs-comment"># 首先必须增加一个`初始化` op 到图中.</span>
init_op = tf.initialize_all_variables()

<span class="hljs-comment"># 启动图, 运行 op</span>
with tf.Session() as sess:
  <span class="hljs-comment"># 运行 'init' op</span>
  sess.run(init_op)
  <span class="hljs-comment"># 打印 'state' 的初始值</span>
  print sess.run(<span class="hljs-keyword">state</span>)
  <span class="hljs-comment"># 运行 op, 更新 'state', 并打印 'state'</span>
  <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>):
    sess.run(update)
    print sess.run(<span class="hljs-keyword">state</span>)

<span class="hljs-comment"># 输出:</span>

<span class="hljs-comment"># 0</span>
<span class="hljs-comment"># 1</span>
<span class="hljs-comment"># 2</span>
<span class="hljs-comment"># 3</span></code></pre></div>
<p>代码中 assign() 操作是图所描绘的表达式的一部分, 正如 add() 操作一样. 所以在调用 run() 执行表达式之前, 它并不会真正执行赋值操作.</p>
<p>通常会将一个统计模型中的参数表示为一组变量. 例如, 你可以将一个神经网络的权重作为某个变量存储在一个 tensor 中. 在训练过程中, 通过重复运行训练图, 更新这个 tensor.</p>
<h1 id="Fetch"><a href="#Fetch" class="headerlink" title="Fetch"></a>Fetch</h1><p>为了取回操作的输出内容, 可以在使用 Session 对象的 run() 调用 执行图时, 传入一些 tensor, 这些 tensor 会帮助你取回结果. 在之前的例子里, 我们只取回了单个节点 state, 但是你也可以取回多个 tensor:</p>
<div class="hljs"><pre><code class="hljs angelscript">input1 = tf.constant(<span class="hljs-number">3.0</span>)
input2 = tf.constant(<span class="hljs-number">2.0</span>)
input3 = tf.constant(<span class="hljs-number">5.0</span>)
<span class="hljs-built_in">int</span>ermed = tf.add(input2, input3)
mul = tf.mul(input1, <span class="hljs-built_in">int</span>ermed)

with tf.Session():
  result = sess.run([mul, <span class="hljs-built_in">int</span>ermed])
  print result

# 输出:
# [<span class="hljs-built_in">array</span>([ <span class="hljs-number">21.</span>], dtype=<span class="hljs-built_in">float</span>32), <span class="hljs-built_in">array</span>([ <span class="hljs-number">7.</span>], dtype=<span class="hljs-built_in">float</span>32)]</code></pre></div>
<h1 id="Feed"><a href="#Feed" class="headerlink" title="Feed"></a>Feed</h1><p> TensorFlow 还提供了 feed 机制, 该机制 可以临时替代图中的任意操作中的 tensor 可以对图中任何操作提交补丁, 直接插入一个 tensor.</p>
<p> feed 使用一个 tensor 值临时替换一个操作的输出结果. 你可以提供 feed 数据作为 run() 调用的参数. feed 只在调用它的方法内有效, 方法结束, feed 就会消失. 最常见的用例是将某些特殊的操作指定为 “feed” 操作, 标记的方法是使用 tf.placeholder() 为这些操作创建占位符.</p>
<div class="hljs"><pre><code class="hljs vim">input1 = <span class="hljs-keyword">tf</span>.placeholder(<span class="hljs-keyword">tf</span>.types.float32)
input2 = <span class="hljs-keyword">tf</span>.placeholder(<span class="hljs-keyword">tf</span>.types.float32)
output = <span class="hljs-keyword">tf</span>.mul(input1, input2)

with <span class="hljs-keyword">tf</span>.Session() <span class="hljs-keyword">as</span> ses<span class="hljs-variable">s:</span>
  <span class="hljs-keyword">print</span> sess.run([output], feed_dict=&#123;input1:[<span class="hljs-number">7</span>.], input2:[<span class="hljs-number">2</span>.]&#125;)

# 输出:
# [array([ <span class="hljs-number">14</span>.], dtype=float32)]</code></pre></div>

